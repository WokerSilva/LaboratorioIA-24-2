\subsection{Análisis equipo}

\begin{itemize}
    \item Marco Silva Huerta 
    
    Para el modelo de Logistic Regression su matriz de confusión muestra un rendimiento bastante bueno con un bajo número de 
    falsos positivos y falsos negativos, eso le da un equilibrio del $91\%$ en la clasificación de ham y spam. Pero para el 
    modelo SVM la precisión en números es del $0.9343$, esto pasa porque SVM tiene menos falsos positivos que Logistic Regression.\\ 

    Ahora cuando volteamos a ver a Decision Tree Classifier, muestra un desempeño aceptable en relación a los dos primeros 
    pues cuenta  con un $87\%$ de exactitud general, esto se pude explicar ya que Los árboles de decisión son propensos al 
    sobreajuste cuando se entrenan con conjuntos de datos complejos o desbalanceados ya que sus nodos al dividirse pueden 
    tener dificultades para  generalizar patrones en datos que no han visto durante el entrenamiento.\\ 

    Finalmente el modelo Random Forest Classifier muestra un rendimiento muy muy bueno, fue el que mayor positivos verdaderos tuvo 
    con 1163 y pese a tener también un $93\%$ en la exactitud del modelo, queda segundo lugar pues tiene un $0.9318$, ligeramente 
    por debajo de SVM pero arriba de su individual árbol de decisión, esto porque Random Forest utiliza múltiples árboles de decisión 
    en lugar de uno solo, la combinación de las predicciones reduce el riesgo de sobreajuste.\\ 

    \item Fernando Mendoza Eslava

    El ajuste de \texttt{class\_weight='balanced'} ha sido esencial en nuestros modelos, permitiendo que estos presten más atención a la clase 
    minoritaria 'spam'. Este enfoque ha ayudado a mejorar el \textit{recall} de la clase minoritaria sin sacrificar significativamente la precisión, 
    un balance crucial en aplicaciones reales donde el costo de predecir erróneamente un 'spam' como 'ham' puede ser alto.
    
    Elegimos utilizar \texttt{TfidfVectorizer} por su capacidad para no solo contar la frecuencia de palabras, sino también ajustar estos conteos 
    basándose en la importancia de las palabras dentro del corpus total del documento. Esta técnica ha probado ser efectiva en resaltar 
    las palabras más relevantes y en minimizar el ruido proveniente de palabras comunes pero irrelevantes.
    
    La evaluación detallada utilizando precisión, \textit{recall}, \textit{F1-score} y matrices de confusión ha revelado la robustez de los modelos SVM y 
    Random Forest, que han mostrado un excelente balance entre precisión y capacidad de \textit{recall}. Estas métricas son fundamentales para 
    entender el verdadero rendimiento en un escenario de clases desbalanceadas.

    \item Carlos Daniel Cortés Jiménez

    Notemos que los modelos como \textit{Random Forest Classifier}, \textit{Logistic Regression} y \textit{Support Vector Machine (SVM)} estos 
    presentan un mejor rendimiendo a comparación del modelo \textit{Decision Tree Classifier} aunque la diferencia no sea tan grande, además 
    la tasa de verdaderos positivos con la que se puede detectar mejor mensajes de tipo ham es el modelo \textit{Random Forest Classifier} con 
    una precisión del $95\%$. Por otro lado el modelo con la mejor detección de mensajes de tipo spam es \textit{Support Vector Machine (SVM)} 
    con un porcentaje del $96\%$.

    Podemos decir entonces que los modelos que tienen el mejor equilibrio entre precisión y recall(sensibilidad) son los mdelos anteriores 
    mencionados siendo Random Forest Classifier y \textit{Support Vector Machine (SVM)}, con porcentajes altos de detección de mensajes 
    de tipo spam y ham, siendo lo que deberiamos de usar a la hora de desarrollar programas que tengan el mejor rendimiento y la mejor precisión.

    \item Luis Enrique Garcia Gomez
    
    Los cuatro modelos de aprendizaje automático evaluados con Regresión Logística, SVM, Bosque Aleatorio y Árbol de Decisión mostraron un buen rendimiento en la clasificación de correos electrónicos spam, que van de entre el 86.9\% y el 93.43\%. Donde la selección del modelo óptimo dependerá de factores como el tamaño y la complejidad del conjunto de datos.


Es importante mencionar que dichos resultados son favorecedores, dado a que se llevó a cabo una adecuada preparación de datos, favoreciendo el rendimiento de los modelos, con técnicas como la exploración de datos, el balanceo de clases, el preprocesamiento, la tokenización y vectorización contribuyendo significativamente.


\begin{itemize} 
    \item Regresión Logística: Este modelo presenta la precisión general más baja (91.39\%), pero tiene un buen equilibrio entre la precisión y la cobertura para ambas clases. También con una baja complejidad, lo que lo hace fácil de implementar y comprender.
    \item SVM: El modelo SVM tiene una precisión general ligeramente superior a la Regresión Logística (93.43\%) y un F1-score ligeramente superior para la clase spam.
    \item Bosque Aleatorio: Con una precisión de 93.18\% este modelo tiene una precisión general similar al SVM (93.06\%) y un buen rendimiento.
    \item Árbol de Decisión: El modelo Árbol de Decisión tiene la precisión general más baja (86.9\%), pero aun así logra identificar la mayoría de los correos electrónicos correctamente, con un mejor desempeño en la clasificación de correos electrónicos spam. 
\end{itemize}


Con las métricas de Precisión, Recall, F1-score, Accuracy y la matriz de confusión, nos permite la elección del modelo óptimo de acuerdo con las necesidades específicas, sí la precisión la prioridad principal, el SVM o el Bosque Aleatorio son buenas opciones. Sí la simplicidad e interpretabilidad del modelo son importantes, la Regresión Logística o el Árbol de Decisión son más adecuados y sí se maneja un conjunto de datos grande o complejo, el Bosque Aleatorio o el SVM son los más robustos.


    \item Sarah Sophía Olivares García

    El modelo de Regresión Logística alcanzó una precisión del $91\%$ y un recall del $92\%$ para la clase spam, con una precisión y         recall del $92\%$ y $91\%$ respectivamente para la clase ham. El F1-score general fue del $91\%$.

    El modelo SVM logró una precisión del $93.43\%$ y un recall del $95\%$ para la clase spam, con una precisión y recall del $95\%$ y         $93.43\%$ respectivamente para la clase ham. El F1-score general fue del $93.21\%$.

    Para el Clasificador de Árboles de Decisión, se obtuvo una precisión del $87\%$ y un recall del $86\%$ para la clase spam, y una         precisión y recall del $88\%$ y $87\%$ respectivamente para la clase ham. El F1-score general fue del $87\%$.

    El Clasificador de Bosques Aleatorios obtuvo una precisión del $95\%$ y un recall del $90\%$ para la clase spam, y una precisión y         recall del $96\%$ y $91\%$ respectivamente para la clase ham. El F1-score general fue del $93\%$.

    Basándonos en las métricas de rendimiento, podemos observar que SVM y Random Forest Classifier mostraron el mejor equilibrio entre         precisión y recall, con una alta capacidad de detección de mensajes de spam y ham

    \item Laura Itzel Tinoco Miguel:
    
    Los modelos Support Vector Machine (SVM) y Random Forest Classifier demostraron ser los más efectivos para la clasificación de mensajes de texto en spam y ham (no spam). SVM logró la mayor precisión general ($93.43\%$) y el mejor recall ($95\%$) para detectar spam. Por otro lado, Random Forest Classifier obtuvo la mayor precisión ($95\%$) y un excelente recall ($91\%$) para identificar mensajes ham. Ambos modelos lograron un equilibrio óptimo entre precisión y recall, superando a los modelos de Regresión Logística y Árbol de Decisión. La técnica \texttt{TfidfVectorizer} y el ajuste de \texttt{class\_weight='balanced'} fueron claves para el buen desempeño de los modelos en un conjunto de datos desbalanceado.

\end{itemize}
