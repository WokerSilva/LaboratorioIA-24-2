\subsection{Análisis equipo}

\begin{itemize}
    \item Marco Silva Huerta 
    
    Para el modelo de Logistic Regression su matriz de confusión muestra un rendimiento bastante bueno con un bajo número de 
    falsos positivos y falsos negativos, eso le da un equilibrio del $91\%$ en la clasificación de ham y spam. Pero para el 
    modelo SVM la precisión en números es del $0.9343$, esto pasa porque SVM tiene menos falsos positivos que Logistic Regression.\\ 

    Ahora cuando volteamos a ver a Decision Tree Classifier, muestra un desempeño aceptable en relación a los dos primeros 
    pues cuenta  con un $87\%$ de exactitud general, esto se pude explicar ya que Los árboles de decisión son propensos al 
    sobreajuste cuando se entrenan con conjuntos de datos complejos o desbalanceados ya que sus nodos al dividirse pueden 
    tener dificultades para  generalizar patrones en datos que no han visto durante el entrenamiento.\\ 

    Finalmente el modelo Random Forest Classifier muestra un rendimiento muy muy bueno, fue el que mayor positivos verdaderos tuvo 
    con 1163 y pese a tener también un $93\%$ en la exactitud del modelo, queda segundo lugar pues tiene un $0.9318$, ligeramente 
    por debajo de SVM pero arriba de su individual árbol de decisión, esto porque Random Forest utiliza múltiples árboles de decisión 
    en lugar de uno solo, la combinación de las predicciones reduce el riesgo de sobreajuste.\\ 

    \item Fernando Mendoza Eslava

    El ajuste de \texttt{class\_weight='balanced'} ha sido esencial en nuestros modelos, permitiendo que estos presten más atención a la clase 
    minoritaria 'spam'. Este enfoque ha ayudado a mejorar el \textit{recall} de la clase minoritaria sin sacrificar significativamente la precisión, 
    un balance crucial en aplicaciones reales donde el costo de predecir erróneamente un 'spam' como 'ham' puede ser alto.
    
    Elegimos utilizar \texttt{TfidfVectorizer} por su capacidad para no solo contar la frecuencia de palabras, sino también ajustar estos conteos 
    basándose en la importancia de las palabras dentro del corpus total del documento. Esta técnica ha probado ser efectiva en resaltar 
    las palabras más relevantes y en minimizar el ruido proveniente de palabras comunes pero irrelevantes.
    
    La evaluación detallada utilizando precisión, \textit{recall}, \textit{F1-score} y matrices de confusión ha revelado la robustez de los modelos SVM y 
    Random Forest, que han mostrado un excelente balance entre precisión y capacidad de \textit{recall}. Estas métricas son fundamentales para 
    entender el verdadero rendimiento en un escenario de clases desbalanceadas.
    
\end{itemize}